# Environment Configuration for Repo2Txt
# Copy this file to .env and fill in your values

# GitHub Access (Optional)
# Required for private repositories and to avoid rate limits
# Get a token at: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_personal_access_token

# LLM Configuration
# Choose your provider: openai, ollama, llamacpp
LLM_PROVIDER=openai

# OpenAI Configuration
# Get your API key at: https://platform.openai.com/api-keys
LLM_API_KEY=your_openai_api_key
LLM_MODEL=gpt-4.1
LLM_TIMEOUT=60

# Ollama Configuration (Alternative)
# Uncomment these lines to use Ollama instead
# LLM_PROVIDER=ollama
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=dummy-key  # Ollama doesn't need a real key
# LLM_MODEL=qwen3:32b
# LLM_TIMEOUT=180

# llama.cpp Configuration (Alternative)
# Uncomment these lines to use llama.cpp server
# LLM_PROVIDER=llamacpp
# LLM_BASE_URL=http://localhost:8080/v1
# LLM_API_KEY=dummy-key  # llama.cpp doesn't need a real key
# LLM_MODEL=devstral
# LLM_TIMEOUT=180

# Note: UI preferences like theme, token budget, and debug mode
# are configured via command-line arguments, not environment variables:
# --theme manhattan/matrix/green/sunset
# --token-budget 50000
# --debug